{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FimHdnOWV5C8"
   },
   "source": [
    "# Fake News Detection using Random Forest Classifier\n",
    "\n",
    "### Objective:\n",
    "Build a machine learning system that detects whether a news article is **Real or Fake**\n",
    "using Natural Language Processing (NLP) techniques and a **Random Forest** classifier.\n",
    "\n",
    "### Workflow Overview:\n",
    "1. Import required libraries and dependencies\n",
    "2. Load and merge real and fake news datasets\n",
    "3. Preprocess the text:\n",
    "   - Combine title, text, and subject\n",
    "   - Clean text using regular expressions\n",
    "   - Remove stopwords\n",
    "   - Apply stemming\n",
    "4. Convert the cleaned text into numerical features using **TF-IDF Vectorization**\n",
    "5. Split data into training and testing sets (80/20 split, stratified)\n",
    "6. Compare multiple models:\n",
    "   - Logistic Regression\n",
    "   - Multinomial Naive Bayes\n",
    "   - Random Forest (chosen based on best performance)\n",
    "7. Train the final model (Random Forest Classifier)\n",
    "8. Evaluate model performance:\n",
    "   - Accuracy, Precision, Recall, F1-score\n",
    "   - Confusion Matrix (with visualization)\n",
    "9. Enable custom input prediction system\n",
    "10. Save the trained model and vectorizer using Pickle\n",
    "\n",
    "### Problem Type:\n",
    "- **Binary Classification**\n",
    "  - `1` → Real News\n",
    "  - `0` → Fake News\n",
    "\n",
    "### Dataset:\n",
    "- Files used: `WELFake_datset.csv`\n",
    "- Columns: `title`, `text`, `subject`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW7sVtkiJjzp"
   },
   "source": [
    "# Step -1\n",
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMkK6skvIIIN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "# Used to extract and read files directly from ZIP archives\n",
    "\n",
    "import re\n",
    "# re (regular expression) library is useful for searching, replacing, or cleaning specific patterns in text.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# stopwords are common words (like a, the, is) that are usually removed from text data because they don’t add much meaning.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# PorterStemmer helps reduce words to their base or root form. e.g., “playing”, “played” → “play”.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Converts text data into numerical format by calculating importance of words (TF-IDF technique).\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle  # For saving the trained model and vectorizer\n",
    "\n",
    "from tqdm.notebook import tqdm  # Progress bar for pandas apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfjD-xuMKBuD"
   },
   "source": [
    "# Step - 2\n",
    "### Downloading Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O_8iYxGJgrj",
    "outputId": "12490695-141f-40fe-f9e6-c43e60795a67"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNfkW-03KNoS",
    "outputId": "74da5142-033f-4594-ee64-adaed357150c"
   },
   "outputs": [],
   "source": [
    "# printing the stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPKyD4PNKWIw"
   },
   "source": [
    "# Step - 3\n",
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NJINsgPuoyM"
   },
   "outputs": [],
   "source": [
    "news_data = pd.read_csv(\"/content/WELFake_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "4dIV-uX4KywB",
    "outputId": "6cc28af0-f4d8-435b-b06d-2c918d11413d"
   },
   "outputs": [],
   "source": [
    "# Print first few rows of the data\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXkPwSylK0Wr",
    "outputId": "7f43fe23-7293-42a8-bf7b-21e4fb74d4eb"
   },
   "outputs": [],
   "source": [
    "# print the dimensions of our dataset (rows , columns)\n",
    "news_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "h1k9pftpK4sX",
    "outputId": "93654db7-b468-4131-d135-bf7e09c8192a"
   },
   "outputs": [],
   "source": [
    "# checking for missing values in dataset\n",
    "news_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJtvqY4MwIu6"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing title or text\n",
    "news_data = news_data.dropna(subset=['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN7LIUKUwLAY"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "news_data = news_data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdEF8Vs1wN0b"
   },
   "outputs": [],
   "source": [
    "# Reset index after dropping rows\n",
    "news_data = news_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klr6lCAEK2fh",
    "outputId": "3b2324b3-3739-4b5e-a443-9bb4898844c4"
   },
   "outputs": [],
   "source": [
    "# Count the number of real (1) and fake (0) news articles in the dataset\n",
    "# This helps check for class balance before training\n",
    "print(news_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTQAfI2vK6ja"
   },
   "outputs": [],
   "source": [
    "# Combine multiple useful columns into a single text feature\n",
    "news_data['content'] = news_data['title'] + \" \" + news_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "yWyFacK0K9m4",
    "outputId": "6f75456b-0884-40a9-fab3-706869f2d0c7"
   },
   "outputs": [],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBR3U03mLDuf"
   },
   "source": [
    "# Step - 4\n",
    "### Stemming\n",
    "Stemming is the process of reducing a word to its root word.\n",
    "\n",
    "- e.g:- \"enjoyed\" , \"enjoyable\" , \"enjoying\" ---> \"enjoy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWjlSCo_LBfc"
   },
   "outputs": [],
   "source": [
    "# Load stopwords once\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSaTK5y_LJX5"
   },
   "outputs": [],
   "source": [
    "# load an instance of Porter Stemmer in a variable\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYgr9SOxLNRj"
   },
   "source": [
    "This function cleans the text, removes stopwords, and applies stemming to reduce words to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voYBgXCYLLL3"
   },
   "outputs": [],
   "source": [
    "# create a function for stemming\n",
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "    # Removes everything except letters (gets rid of numbers, punctuation, etc.)\n",
    "    # ^ means exclude everthing else except ; [a-zA-Z] matches all letters; re.sub replaces non-letters in 'content' with spaces\n",
    "\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Converts all text to lowercase\n",
    "\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Splits the sentence into individual words\n",
    "\n",
    "    stemmed_content = [port_stem.stem(word)\n",
    "                       for word in stemmed_content\n",
    "                       if not word in stop_words]\n",
    "    # Removes common stopwords and stems each word to its root form\n",
    "\n",
    "    stemmed_content = \" \".join(stemmed_content)\n",
    "    # Joins the cleaned words back into a single string\n",
    "\n",
    "    return stemmed_content\n",
    "    # Returns the final preprocessed text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkaHkh8nLUZ0"
   },
   "source": [
    "- `tqdm` is a Python library that shows a progress bar for loops — useful for long operations like text preprocessing.\n",
    "\n",
    "- `tqdm.notebook` version is specifically designed for Jupyter/Colab notebooks with nice formatting.\n",
    "\n",
    "- `tqdm.pandas()` integrates `tqdm` with pandas, so you can use `.progress_apply()` on DataFrame columns.\n",
    "\n",
    "- `news_data['content'].progress_apply(stemming)` applies your custom `stemming()` function to every row in the `content` column, while showing live progress.\n",
    "\n",
    "- This helps you track the progress of the stemming operation and estimate how long it will take to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f740d63dfdd14dd2b73462059569f494",
      "406b0f6bf3dc4a10977bbe73457fb4df",
      "04c71edbf94c4e7986e077aea13b6947",
      "4e59f453101f486dbfad36da8fc0350d",
      "d029529ef0894b85ac5943d461a7c9d1",
      "b7d9082ca616428788b987b34da689b9",
      "26ba24f40f364ff495029e776dac536f",
      "83d8740ae9e14fe486fd5f8ee213fa7f",
      "109ddfa7ecf644c4a3f8b173939b6106",
      "310eb81eea73453d823b8a59842a3dd2",
      "7776e6dcbfba49ce814db2c94bcbbeb0"
     ]
    },
    "id": "kWpTbSVeLQtO",
    "outputId": "3fca4b24-16e6-4438-b00a-d0cfef787233"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()  # activate tqdm with pandas\n",
    "\n",
    "news_data['content'] = news_data['content'].progress_apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeJftuJtL8pD",
    "outputId": "c127de66-0386-4268-e9f6-318cc83c3af6"
   },
   "outputs": [],
   "source": [
    "# printing the content column\n",
    "print(news_data['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1yoTMi8MCBq"
   },
   "source": [
    "# Step - 5\n",
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsN1t5rXMGIc"
   },
   "source": [
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** converts the raw text into numerical feature vectors, giving more importance to rare but meaningful words in the corpus.\n",
    "\n",
    "- Initialize TF-IDF Vectorizer to convert text into numerical features\n",
    "- Removes English stopwords (common words that add little meaning)\n",
    "- Limits features to top 10000 most important words/ngrams\n",
    "- Considers unigrams and bigrams (single words and pairs of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoH1hqgUMEI5"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',  # Removes common noise words\n",
    "    max_features=10000,     # Prevents overfitting & keeps model lightweight\n",
    "    ngram_range=(1, 2)     # Captures both single words AND pairs of words (context!)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2v-XyZJMWn2"
   },
   "outputs": [],
   "source": [
    "# Fit the vectorizer on the text and transform it into TF-IDF feature matrix\n",
    "X_text = vectorizer.fit_transform(news_data['content'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13RJuYNsMXiO"
   },
   "source": [
    "# Step - 6\n",
    "### Feature and Target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wBSHl_OMa3I"
   },
   "outputs": [],
   "source": [
    "# Features\n",
    "X = X_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dkn3zmQmMdOo"
   },
   "outputs": [],
   "source": [
    "# Target\n",
    "Y = news_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3NMYVuQMfKU",
    "outputId": "1f23c616-a7a5-41c3-8993-29570e493e9d"
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXMGQdyyMhXP",
    "outputId": "30b65b6a-9314-4d9a-838c-2324f493ada3"
   },
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjdUM_IEMlfF"
   },
   "source": [
    "# Step - 7\n",
    "### Train Test Split\n",
    "\n",
    "- Splitting data into training and testing sets\n",
    "- 80% training data, 20% testing data\n",
    "- Stratify to keep label distribution consistent in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8u7yjxsMql2"
   },
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(\n",
    "    X , Y , test_size= 0.2 , random_state=2 , stratify= Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4DJ1huLNLmn"
   },
   "source": [
    "# Step - 8\n",
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAEirV9RNJRW",
    "outputId": "2ffc5ab0-9b79-4930-a916-3e489d3b933e"
   },
   "outputs": [],
   "source": [
    "# Create a list of models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Iterate through the list to get predictions from each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)   # Fit the model\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # Print the Performance of each model\n",
    "    print(f\"\\n{name} Performance \")\n",
    "    print(\"Accuracy:\", accuracy_score(Y_test, preds))\n",
    "    print(\"Classification Report:\\n\", classification_report(Y_test, preds))\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk02xZv-RrAt"
   },
   "source": [
    "- Random Forest achieved the highest accuracy (~95.6%) and showed balanced precision, recall, and F1-score.\n",
    "\n",
    "- Logistic Regression also performed well (~94.6%) but slightly below Random Forest.\n",
    "\n",
    "- Naive Bayes showed lower accuracy (~86.2%) and is less suitable for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUgWb6WRR407"
   },
   "source": [
    "# Step - 9\n",
    "### Model Training\n",
    "Initialize and train the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuUKlBEDNyH0"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "7KoTxUbnSkgR",
    "outputId": "864fbcf6-6774-4141-de3b-474bcb92c5ca"
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1ZeGjXkSolQ"
   },
   "source": [
    "# Step - 10\n",
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55Q7nZnETaB2"
   },
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "X_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQMqazD9TcFp"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "training_data_accuracy = accuracy_score( Y_train , X_train_pred)\n",
    "report = classification_report(Y_train, X_train_pred)\n",
    "conf_matrix = confusion_matrix(Y_train, X_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSGt7WZD2_RB",
    "outputId": "8bddabf9-d650-40bb-fa13-2d3b2d071e2c"
   },
   "outputs": [],
   "source": [
    "print(f\"Training Data Accuracy is : {training_data_accuracy}\")\n",
    "print(f\"Classification Report is : {report}\")\n",
    "print(f\"Confusion Matrix is : {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM9KRRWJSpA6"
   },
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "X_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ-F8zaoSq6I"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "test_data_accuracy = accuracy_score( Y_test , X_test_pred)\n",
    "report_test = classification_report(Y_test, X_test_pred)\n",
    "conf_matrix_test = confusion_matrix(Y_test, X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0OU18GET4p1",
    "outputId": "5caeb24d-3590-4cb4-fc50-5ec976a97739"
   },
   "outputs": [],
   "source": [
    "print(f\"Test Data Accuracy is : {test_data_accuracy}\")\n",
    "print(f\"Classification Report is : {report_test}\")\n",
    "print(f\"Confusion Matrix is : {conf_matrix_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH1aLBmHSuaf"
   },
   "source": [
    "# Step - 11\n",
    "### Visualization - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "HTpgqWAhStAy",
    "outputId": "bc413190-bac8-4dfc-957d-9de5224efa94"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test , annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd1OQpQjS0lF"
   },
   "source": [
    "# Step - 12\n",
    "### Making a Custom Input System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uz8EQsjbS1Ap"
   },
   "outputs": [],
   "source": [
    "def predict_custom_news(news_text, vectorizer, model):\n",
    "    # Preprocess the input using the same stemming function\n",
    "    stemmed_text = stemming(news_text)\n",
    "    vectorized_text = vectorizer.transform([stemmed_text])\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    return \"Real\" if prediction[0] == 1 else \"Fake\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1XkotKXU73Z"
   },
   "source": [
    "### Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhPY-NK6S3T3",
    "outputId": "63f39837-6e22-4f0e-de5c-da41c95396f5"
   },
   "outputs": [],
   "source": [
    "sample_news = \"Breaking: President gives major update on national policy.\"\n",
    "result = predict_custom_news(sample_news, vectorizer, model)\n",
    "print(f\"\\nPrediction for custom news input: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj5HYdhCTBbo"
   },
   "source": [
    "# Step - 13\n",
    "### Save the model and vectorizer using pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAfxoURHS6sh"
   },
   "outputs": [],
   "source": [
    "with open(\"logistic_regression_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
