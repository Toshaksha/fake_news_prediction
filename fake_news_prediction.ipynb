{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FimHdnOWV5C8"
   },
   "source": [
    "# Fake News Detection using Logistic Regression Model\n",
    "\n",
    "### Objective:\n",
    "Build a machine learning system that detects whether a news article is **Real or Fake**\n",
    "using Natural Language Processing (NLP) techniques and a **Logistic Regression** model.\n",
    "\n",
    "### Workflow Overview:\n",
    "1. Import required libraries and dependencies\n",
    "2. Load and merge real and fake news datasets\n",
    "3. Preprocess the text:\n",
    "   - Combine title, text, and subject\n",
    "   - Clean text using regular expressions\n",
    "   - Remove stopwords\n",
    "   - Apply stemming\n",
    "4. Convert the cleaned text into numerical features using **TF-IDF Vectorization**\n",
    "5. Split data into training and testing sets (80/20 split, stratified)\n",
    "6. Compare multiple models:\n",
    "   - Logistic Regression\n",
    "   - Multinomial Naive Bayes\n",
    "   - Random Forest (chosen based on best performance)\n",
    "7. Train the final model\n",
    "8. Evaluate model performance:\n",
    "   - Accuracy, Precision, Recall, F1-score\n",
    "   - Confusion Matrix (with visualization)\n",
    "9. Enable custom input prediction system\n",
    "10. Save the trained model and vectorizer using Pickle\n",
    "\n",
    "### Problem Type:\n",
    "- **Binary Classification**\n",
    "  - `1` → Real News\n",
    "  - `0` → Fake News\n",
    "\n",
    "### Dataset:\n",
    "- Files used: `WELFake_datset.csv`\n",
    "- Columns: `title`, `text`, `subject`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW7sVtkiJjzp"
   },
   "source": [
    "# Step -1\n",
    "### Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMkK6skvIIIN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import zipfile\n",
    "# Used to extract and read files directly from ZIP archives\n",
    "\n",
    "import re\n",
    "# re (regular expression) library is useful for searching, replacing, or cleaning specific patterns in text.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "# stopwords are common words (like a, the, is) that are usually removed from text data because they don’t add much meaning.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "# PorterStemmer helps reduce words to their base or root form. e.g., “playing”, “played” → “play”.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Converts text data into numerical format by calculating importance of words (TF-IDF technique).\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle  # For saving the trained model and vectorizer\n",
    "\n",
    "from tqdm.notebook import tqdm  # Progress bar for pandas apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfjD-xuMKBuD"
   },
   "source": [
    "# Step - 2\n",
    "### Downloading Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O_8iYxGJgrj",
    "outputId": "c37e7b7d-656d-4d07-c7e5-8ed55c7b1cdc"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rNfkW-03KNoS",
    "outputId": "675ed198-2072-4fd9-bdfd-4101547b59bf"
   },
   "outputs": [],
   "source": [
    "# printing the stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPKyD4PNKWIw"
   },
   "source": [
    "# Step - 3\n",
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NJINsgPuoyM"
   },
   "outputs": [],
   "source": [
    "news_data = pd.read_csv(\"/content/WELFake_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "4dIV-uX4KywB",
    "outputId": "62a230c2-1222-41dd-bda2-7833a29e65e1"
   },
   "outputs": [],
   "source": [
    "# Print first few rows of the data\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXkPwSylK0Wr",
    "outputId": "0f1bd0b5-93d8-47d6-f6de-1c0f7e5aca45"
   },
   "outputs": [],
   "source": [
    "# print the dimensions of our dataset (rows , columns)\n",
    "news_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "h1k9pftpK4sX",
    "outputId": "63686eeb-8336-42d2-e67a-ddc7dee70e86"
   },
   "outputs": [],
   "source": [
    "# checking for missing values in dataset\n",
    "news_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJtvqY4MwIu6"
   },
   "outputs": [],
   "source": [
    "# Drop rows with missing title or text\n",
    "news_data = news_data.dropna(subset=['title', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN7LIUKUwLAY"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "news_data = news_data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdEF8Vs1wN0b"
   },
   "outputs": [],
   "source": [
    "# Reset index after dropping rows\n",
    "news_data = news_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "klr6lCAEK2fh",
    "outputId": "76a68712-cbea-4fa9-b013-af3b8e2ac85f"
   },
   "outputs": [],
   "source": [
    "# Count the number of real (1) and fake (0) news articles in the dataset\n",
    "# This helps check for class balance before training\n",
    "print(news_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dTQAfI2vK6ja"
   },
   "outputs": [],
   "source": [
    "# Combine multiple useful columns into a single text feature\n",
    "news_data['content'] = news_data['title'] + \" \" + news_data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "yWyFacK0K9m4",
    "outputId": "94ac8420-d7ea-4871-c03a-e041ee93768c"
   },
   "outputs": [],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBR3U03mLDuf"
   },
   "source": [
    "# Step - 4\n",
    "### Stemming\n",
    "Stemming is the process of reducing a word to its root word.\n",
    "\n",
    "- e.g:- \"enjoyed\" , \"enjoyable\" , \"enjoying\" ---> \"enjoy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WWjlSCo_LBfc"
   },
   "outputs": [],
   "source": [
    "# Load stopwords once\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSaTK5y_LJX5"
   },
   "outputs": [],
   "source": [
    "# load an instance of Porter Stemmer in a variable\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYgr9SOxLNRj"
   },
   "source": [
    "This function cleans the text, removes stopwords, and applies stemming to reduce words to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voYBgXCYLLL3"
   },
   "outputs": [],
   "source": [
    "# create a function for stemming\n",
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]', ' ', content)\n",
    "    # Removes everything except letters (gets rid of numbers, punctuation, etc.)\n",
    "    # ^ means exclude everthing else except ; [a-zA-Z] matches all letters; re.sub replaces non-letters in 'content' with spaces\n",
    "\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    # Converts all text to lowercase\n",
    "\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    # Splits the sentence into individual words\n",
    "\n",
    "    stemmed_content = [port_stem.stem(word)\n",
    "                       for word in stemmed_content\n",
    "                       if not word in stop_words]\n",
    "    # Removes common stopwords and stems each word to its root form\n",
    "\n",
    "    stemmed_content = \" \".join(stemmed_content)\n",
    "    # Joins the cleaned words back into a single string\n",
    "\n",
    "    return stemmed_content\n",
    "    # Returns the final preprocessed text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkaHkh8nLUZ0"
   },
   "source": [
    "- `tqdm` is a Python library that shows a progress bar for loops — useful for long operations like text preprocessing.\n",
    "\n",
    "- `tqdm.notebook` version is specifically designed for Jupyter/Colab notebooks with nice formatting.\n",
    "\n",
    "- `tqdm.pandas()` integrates `tqdm` with pandas, so you can use `.progress_apply()` on DataFrame columns.\n",
    "\n",
    "- `news_data['content'].progress_apply(stemming)` applies your custom `stemming()` function to every row in the `content` column, while showing live progress.\n",
    "\n",
    "- This helps you track the progress of the stemming operation and estimate how long it will take to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "acffff11b9064cdebf21211b17cc9bb4",
      "e463dff8ef9243b78e15fb278100452a",
      "ebc35de39053497fa564a66e6888722e",
      "16ddbc3303cb413a9b61dacb56786ed3",
      "1d6030ce100748a19be4540c4e1172f4",
      "2513669836204906bd5f5b0b79f86b76",
      "cf55ba3de7b04402b9ef32e0f82595c1",
      "bc4c89ad5c044dec955520f362b8cd7c",
      "25bd8f897d3b4cb1a639268e9bfdca40",
      "124144bf27b945b2acf7d4636f10dc57",
      "4e067f1f9c374855aa51d81ec9cec3ff"
     ]
    },
    "id": "kWpTbSVeLQtO",
    "outputId": "c120541c-2e7c-4b1d-dfd9-4a3f3ab57864"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()  # activate tqdm with pandas\n",
    "\n",
    "news_data['content'] = news_data['content'].progress_apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeJftuJtL8pD",
    "outputId": "79404345-d0d9-4be2-9064-3cbb1661d43c"
   },
   "outputs": [],
   "source": [
    "# printing the content column\n",
    "print(news_data['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1yoTMi8MCBq"
   },
   "source": [
    "# Step - 5\n",
    "### TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsN1t5rXMGIc"
   },
   "source": [
    "**TF-IDF (Term Frequency-Inverse Document Frequency)** converts the raw text into numerical feature vectors, giving more importance to rare but meaningful words in the corpus.\n",
    "\n",
    "- Initialize TF-IDF Vectorizer to convert text into numerical features\n",
    "- Removes English stopwords (common words that add little meaning)\n",
    "- Limits features to top 10000 most important words/ngrams\n",
    "- Considers unigrams and bigrams (single words and pairs of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AoH1hqgUMEI5"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',  # Removes common noise words\n",
    "    max_features=10000,     # Prevents overfitting & keeps model lightweight\n",
    "    ngram_range=(1, 2)     # Captures both single words AND pairs of words (context!)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2v-XyZJMWn2"
   },
   "outputs": [],
   "source": [
    "# Fit the vectorizer on the text and transform it into TF-IDF feature matrix\n",
    "X_text = vectorizer.fit_transform(news_data['content'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13RJuYNsMXiO"
   },
   "source": [
    "# Step - 6\n",
    "### Feature and Target split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wBSHl_OMa3I"
   },
   "outputs": [],
   "source": [
    "# Features\n",
    "X = X_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dkn3zmQmMdOo"
   },
   "outputs": [],
   "source": [
    "# Target\n",
    "Y = news_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3NMYVuQMfKU",
    "outputId": "8dd02848-06a0-4fef-901d-e1056dade076"
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXMGQdyyMhXP",
    "outputId": "7efbd4a0-13f3-4b73-9d77-38d587a1b06e"
   },
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjdUM_IEMlfF"
   },
   "source": [
    "# Step - 7\n",
    "### Train Test Split\n",
    "\n",
    "- Splitting data into training and testing sets\n",
    "- 80% training data, 20% testing data\n",
    "- Stratify to keep label distribution consistent in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q8u7yjxsMql2"
   },
   "outputs": [],
   "source": [
    "X_train , X_test , Y_train , Y_test = train_test_split(\n",
    "    X , Y , test_size= 0.2 , random_state=2 , stratify= Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4DJ1huLNLmn"
   },
   "source": [
    "# Step - 8\n",
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAEirV9RNJRW",
    "outputId": "eee5c8d2-86c7-4c36-e43d-ec6a54eca0b8"
   },
   "outputs": [],
   "source": [
    "# Create a list of models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Iterate through the list to get predictions from each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, Y_train)   # Fit the model\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    # Print the Performance of each model\n",
    "    print(f\"\\n{name} Performance \")\n",
    "    print(\"Accuracy:\", accuracy_score(Y_test, preds))\n",
    "    print(\"Classification Report:\\n\", classification_report(Y_test, preds))\n",
    "    print(\"-------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk02xZv-RrAt"
   },
   "source": [
    "- Random Forest achieved the highest accuracy (~95.6%) and showed balanced precision, recall, and F1-score. However, it caused overfitting on our dataset, which could reduce the model's ability to generalize well to unseen data.\n",
    "\n",
    "- Logistic Regression also performed well (~94.6%) with a slightly lower accuracy but demonstrated better generalization and stability. Therefore, we selected Logistic Regression as our final model to avoid overfitting issues.\n",
    "\n",
    "- Naive Bayes showed lower accuracy (~86.2%) and was less suitable for this task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUgWb6WRR407"
   },
   "source": [
    "# Step - 9\n",
    "### Model Training\n",
    "Initialize and train the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuUKlBEDNyH0"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "7KoTxUbnSkgR",
    "outputId": "6b8a8273-7d8c-48d5-c51e-484c0f7d9f80"
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1ZeGjXkSolQ"
   },
   "source": [
    "# Step - 10\n",
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55Q7nZnETaB2"
   },
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "X_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQMqazD9TcFp"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "training_data_accuracy = accuracy_score( Y_train , X_train_pred)\n",
    "report = classification_report(Y_train, X_train_pred)\n",
    "conf_matrix = confusion_matrix(Y_train, X_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSGt7WZD2_RB",
    "outputId": "28a800c5-b043-43b2-ff78-addfa332c2d2"
   },
   "outputs": [],
   "source": [
    "print(f\"Training Data Accuracy is : {training_data_accuracy}\")\n",
    "print(f\"Classification Report is : {report}\")\n",
    "print(f\"Confusion Matrix is : {conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DM9KRRWJSpA6"
   },
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "X_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ-F8zaoSq6I"
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "test_data_accuracy = accuracy_score( Y_test , X_test_pred)\n",
    "report_test = classification_report(Y_test, X_test_pred)\n",
    "conf_matrix_test = confusion_matrix(Y_test, X_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0OU18GET4p1",
    "outputId": "c5b63e5a-c21c-4ab8-c31a-ab00bdde6045"
   },
   "outputs": [],
   "source": [
    "print(f\"Test Data Accuracy is : {test_data_accuracy}\")\n",
    "print(f\"Classification Report is : {report_test}\")\n",
    "print(f\"Confusion Matrix is : {conf_matrix_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iH1aLBmHSuaf"
   },
   "source": [
    "# Step - 11\n",
    "### Visualization - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "HTpgqWAhStAy",
    "outputId": "0208ea1e-3dc0-4efe-f9ae-450642fc2966"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix_test , annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd1OQpQjS0lF"
   },
   "source": [
    "# Step - 12\n",
    "### Making a Custom Input System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uz8EQsjbS1Ap"
   },
   "outputs": [],
   "source": [
    "def predict_custom_news(news_text, vectorizer, model):\n",
    "    # Preprocess the input using the same stemming function\n",
    "    stemmed_text = stemming(news_text)\n",
    "    vectorized_text = vectorizer.transform([stemmed_text])\n",
    "    prediction = model.predict(vectorized_text)\n",
    "    return \"Real\" if prediction[0] == 1 else \"Fake\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1XkotKXU73Z"
   },
   "source": [
    "### Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhPY-NK6S3T3",
    "outputId": "a32325a8-ba76-432d-884b-b2e4ed02104c"
   },
   "outputs": [],
   "source": [
    "sample_news = \"Breaking: President gives major update on national policy.\"\n",
    "result = predict_custom_news(sample_news, vectorizer, model)\n",
    "print(f\"\\nPrediction for custom news input: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj5HYdhCTBbo"
   },
   "source": [
    "# Step - 13\n",
    "### Save the model and vectorizer using pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAfxoURHS6sh"
   },
   "outputs": [],
   "source": [
    "with open(\"logistic_regression_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
